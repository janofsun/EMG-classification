{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":109371,"status":"ok","timestamp":1677034853922,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"I7b7-saL468y","outputId":"667209e7-686b-46eb-a881-b4fadfdd09d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting EMD-signal\n","  Downloading EMD_signal-1.4.0-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (1.7.3)\n","Requirement already satisfied: tqdm==4.64.* in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (4.64.1)\n","Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (1.21.6)\n","Collecting pathos>=0.2.1\n","  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ppft>=1.7.6.6\n","  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess>=0.70.14\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from pathos>=0.2.1->EMD-signal) (0.3.6)\n","Collecting pox>=0.3.2\n","  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\n","Installing collected packages: ppft, pox, multiprocess, pathos, EMD-signal\n","Successfully installed EMD-signal-1.4.0 multiprocess-0.70.14 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install EMD-signal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mt_pjqvw2LQA"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import time\n","import scipy\n","import scipy.io\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim\n","from torch.utils import data\n","from torch.autograd import Variable\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from PyEMD import EMD\n","from PyEMD import EEMD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"shx-uTzS4MIY"},"outputs":[],"source":["import sys    \n","sys_path = '/content/drive/MyDrive/EMG-classification'\n","sys.path.append(sys_path)\n","from util import *\n","from dataloader import *\n","from model import *"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7226,"status":"ok","timestamp":1677035006862,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"q5TWecP4lvJf","outputId":"23e65205-9177-45d3-941d-404266b56b88"},"outputs":[{"output_type":"stream","name":"stdout","text":["label shape:(5746, 1)\n","record_data.shape:(5746, 1200)\n","\n"]}],"source":["# DataLoader\n","\n","record_data0501 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0501.npy')\n","record_data0502 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0502.npy')\n","record_data0503 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0503.npy')\n","record_data0505 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0505.npy')\n","record_data0506 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0506.npy')\n","labels0501 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0501.npy')\n","labels0502 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0502.npy')\n","labels0503 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0503.npy')\n","labels0505 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0505.npy')\n","labels0506 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0506.npy')\n","\n","signal0501 = record_data0501.flatten()\n","signal0502 = record_data0502.flatten()\n","signal0503 = record_data0503.flatten()\n","signal0505 = record_data0505.flatten()\n","signal0506 = record_data0506.flatten()\n","\n","assert (len(signal0501) == record_data0501.shape[0] * record_data0501.shape[1])\n","assert (len(signal0502) == record_data0502.shape[0] * record_data0502.shape[1])\n","assert (len(signal0503) == record_data0503.shape[0] * record_data0503.shape[1])\n","assert (len(signal0505) == record_data0505.shape[0] * record_data0505.shape[1])\n","assert (len(signal0506) == record_data0506.shape[0] * record_data0506.shape[1])\n","print(\"label shape:{}\\nrecord_data.shape:{}\\n\".format(labels0501.shape, record_data0501.shape))\n","assert (len(labels0501) == record_data0501.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":214,"status":"ok","timestamp":1677035034068,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"kQvxHalu7IjP","outputId":"1c6f48ac-4d8d-4e6a-bf12-fa3679e183be"},"outputs":[{"output_type":"stream","name":"stdout","text":["train data:(25229, 1200)\n","test data:(5746, 1200)\n","\n"]}],"source":["def save_model(path, epoch, model, optimizer):\n","    ckpt = {\n","    \"epoch\" : epoch,\n","    \"model_state_dict\" : model.state_dict(),\n","    \"optimizer_state_dict\" : optimizer.state_dict(),\n","    # \"scheduler_state_dict\" : scheduler.state_dict(),\n","    }\n","    print(\"saving model to:\", path)\n","    torch.save(ckpt,path)\n","# path = '/content/drive/MyDrive/EMG-classification/logs/eemd0129/test_eemd_ep' + str(epoch) + \".pt\"\n","# save_model(path, epoch, model, optimizer)\n","\n","train_label = np.concatenate((labels0502, labels0503, labels0505, labels0506), axis=0)\n","train_record_data = np.concatenate((record_data0502, record_data0503, record_data0505, record_data0506), axis=0)\n","train_signal = np.concatenate((signal0502, signal0503, signal0505, signal0506))\n","assert train_label.shape[0] == train_record_data.shape[0]\n","print(\"train data:{}\\ntest data:{}\\n\".format(train_record_data.shape, record_data0501.shape))\n","val_record_data, val_signal, val_label = record_data0501, signal0501, labels0501\n","\n","eemd = EEMD()\n","emd = eemd.EMD\n","emd.extrema_detection=\"parabol\"\n","fs = np.linspace(0,1,1200)"]},{"cell_type":"code","source":["class FocalLoss(nn.Module):\n","    def __init__(self, gamma=0, alpha=None, size_average=True):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        if isinstance(alpha,(float,int,float)): self.alpha = torch.Tensor([alpha,1-alpha])\n","        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n","        self.size_average = size_average\n","\n","    def forward(self, input, target):\n","        if input.dim()>2:\n","            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n","            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n","            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n","        target = target.view(-1,1)\n","\n","        logpt = F.log_softmax(input)\n","        logpt = logpt.gather(1,target)\n","        logpt = logpt.view(-1)\n","        pt = Variable(logpt.data.exp())\n","\n","        if self.alpha is not None:\n","            if self.alpha.type()!=input.data.type():\n","                self.alpha = self.alpha.type_as(input.data)\n","            at = self.alpha.gather(0,target.data.view(-1))\n","            logpt = logpt * Variable(at)\n","\n","        loss = -1 * (1-pt)**self.gamma * logpt\n","        if self.size_average: return loss.mean()\n","        else: return loss.sum()"],"metadata":{"id":"I513QamEErH5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7ASzAQD2S8r","outputId":"476fc693-21b0-4528-d70d-a34e1b0ec0b8"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-341bab4101f7>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  logpt = F.log_softmax(input)\n"]},{"output_type":"stream","name":"stdout","text":["\n","************************************************************************************************\n","Epoch 1/20:, Train Loss 0.0084, Learning Rate 0.0010\n","train_acc:0.8487532734870911\n","\n","\n","************************************************************************************************\n","Epoch 1/20:\n","test_acc:0.569265604019165\n","\n","\n","************************************************************************************************\n","Epoch 2/20:, Train Loss 0.0130, Learning Rate 0.0010\n","train_acc:0.7378385663032532\n","\n","\n","************************************************************************************************\n","Epoch 3/20:, Train Loss 0.0139, Learning Rate 0.0010\n","train_acc:0.7407851219177246\n","\n","\n","************************************************************************************************\n","Epoch 3/20:\n","test_acc:0.569265604019165\n","\n","\n","************************************************************************************************\n","Epoch 4/20:, Train Loss 0.0170, Learning Rate 0.0010\n","train_acc:0.6940397620201111\n","\n","\n","************************************************************************************************\n","Epoch 5/20:, Train Loss 0.0152, Learning Rate 0.0010\n","train_acc:0.7634708881378174\n","\n","\n","************************************************************************************************\n","Epoch 5/20:\n","test_acc:0.569265604019165\n","\n","\n","************************************************************************************************\n","Epoch 6/20:, Train Loss 0.0125, Learning Rate 0.0010\n","train_acc:0.837410032749176\n","\n","\n","************************************************************************************************\n","Epoch 7/20:, Train Loss 0.0129, Learning Rate 0.0010\n","train_acc:0.7683306336402893\n","\n"]}],"source":["# input is added with window\n","eps = 1\n","input_size = 129\n","#set hidden size\n","hidden_size = 256\n","n_class = 9\n","learning_rate = 0.01\n","max_epochs = 20\n","middle_features = 128\n","model = Netone(num_classes=n_class, hidden_size=input_size, num_layers=1, middle_feature=middle_features) #num_classes, hidden_size, num_layers, bidirectional, middle_feature\n","#model.cuda()\n","# criterion = nn.CrossEntropyLoss()\n","criterion = FocalLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","train_acc = []\n","val_acc = []\n","\n","for epoch in range(max_epochs):\n","    correct_all = 0\n","    total_loss = 0\n","    train_length = 0\n","    predicted_train_csv = []\n","    real_train_csv = []\n","\n","    for batch_idx in range(0,train_record_data.shape[0],eps):\n","        # tic = time.perf_counter()\n","        if batch_idx > train_record_data.shape[0]-eps: break\n","        train_eIMFs = train_signal[1200*batch_idx:1200*(batch_idx+eps)+1]\n","        train_raw = spectro(train_record_data[batch_idx:batch_idx+eps], train_eIMFs, 100, 256)\n","        train_raw = torch.from_numpy(train_raw)\n","        label_raw = train_label[batch_idx:batch_idx+eps]\n","        # print(\"train_raw shape:{}\\n label_raw shape:{}\".format(train_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","        label = np.repeat(label_raw, train_raw.shape[-1])\n","        label = torch.from_numpy(label)\n","        train_set = train_raw.permute(0, 2, 1)\n","        train_set = train_set.reshape(train_set.shape[0]*train_set.shape[1], -1)\n","        # print(\"train_set shape:{}\\nlabel shape:{}\\n\".format(train_set.shape, label.shape)) # [310284, 129]\n","\n","        batch_x = torch.unsqueeze(train_set, dim=0) # [1, 263736, 129]\n","        batch_x = Variable(batch_x.float())  # .cuda()\n","        batch_y = label.long()\n","\n","        optimizer.zero_grad()\n","        output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","        # toc = time.perf_counter()\n","        # print(f\"test epochs time in {toc - tic:0.4f} seconds\")\n","\n","        _, predicted_train = torch.max(output.data, 1)\n","        assert(len(predicted_train)==len(batch_y))\n","        correct_all += sum(batch_y.eq(predicted_train))\n","        train_length += len(batch_y)\n","\n","        predicted_train_csv.append(predicted_train.cpu().detach().numpy())\n","        real_train_csv.append(batch_y.cpu().detach().numpy())\n","\n","        loss = criterion(output, batch_y.squeeze())#.float().reshape(-1, 1)\n","        total_loss += loss\n","        loss.backward()\n","        optimizer.step()\n","\n","    np.save('/content/drive/MyDrive/EMG-classification/logs/eemd_focal/val01_train_pred_'+ str(correct_all / train_length) + '.npy', predicted_train_csv)\n","    np.save('/content/drive/MyDrive/EMG-classification/logs/eemd_focal/val01_train_real_'+ str(correct_all / train_length) + '.npy', real_train_csv)\n","\n","    print('\\n************************************************************************************************')\n","    print(\"Epoch {}/{}:, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n","        epoch+1,\n","        max_epochs,\n","        float(total_loss / train_length),\n","        float(optimizer.param_groups[0]['lr'])))\n","    print('train_acc:{}\\n'.format(correct_all/train_length))\n","\n","    if epoch%2==0:\n","        correct_all = 0\n","        predicted_val_csv = []\n","        real_val_csv = []\n","        val_length = 0\n","        for batch_idx in range(0,val_record_data.shape[0],eps):\n","            # tic = time.perf_counter()\n","            if batch_idx > val_record_data.shape[0]-eps: break\n","            val_eIMFs = eemd.eemd(val_signal[1200*batch_idx:1200*(batch_idx+eps)+1])\n","            val_raw = spectro(val_record_data[batch_idx:batch_idx+eps], val_eIMFs[0], 100, 256)\n","            val_raw = torch.from_numpy(val_raw)\n","            label_raw = val_label[batch_idx:batch_idx+eps]\n","            # print(\"val_raw shape:{}\\n label_raw shape:{}\".format(val_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","            label = np.repeat(label_raw, val_raw.shape[-1])\n","            label = torch.from_numpy(label)\n","            val_set = val_raw.permute(0, 2, 1)\n","            val_set = val_set.reshape(val_set.shape[0]*val_set.shape[1], -1)\n","            # print(\"val_set shape:{}\\nlabel shape:{}\\n\".format(val_set.shape, label.shape)) # [310284, 129]\n","\n","            batch_x = torch.unsqueeze(val_set, dim=0) # [1, 263736, 129]\n","            batch_x = Variable(batch_x.float())  # .cuda()\n","            batch_y = label.long()\n","\n","            output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","            # toc = time.perf_counter()\n","            # print(f\"Test time cost in {toc - tic:0.4f} seconds\")\n","\n","            _, predicted_val = torch.max(output.data, 1)\n","            # print(\"predicted_val shape:{}\\nbatch_y shape:{}\\n\".format(predicted_val.shape, batch_y.shape))\n","            # if len(predicted_val)!=len(batch_y): \n","            #   print(\"label shape:{}\\nval_raw shape:{}\\nlabel_raw shape:{}\".format(label.shape, val_raw.shape, label_raw.shape))\n","            correct_all += sum(batch_y.eq(predicted_val))\n","            val_length += len(batch_y)\n","            predicted_val_csv.append(predicted_val.cpu().detach().numpy())\n","            real_val_csv.append(batch_y.cpu().detach().numpy())\n","\n","        print('\\n************************************************************************************************')\n","        print(\"Epoch {}/{}:\\ntest_acc:{}\\n\".format(epoch+1, max_epochs, correct_all/val_length))\n","\n","        np.save('/content/drive/MyDrive/EMG-classification/logs/eemd_focal/val01_val_pred_'+ str(correct_all / val_length) + '.npy', predicted_val_csv)\n","        np.save('/content/drive/MyDrive/EMG-classification/logs/eemd_focal/val01_val_real_'+ str(correct_all / val_length) + '.npy', real_val_csv)"]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}