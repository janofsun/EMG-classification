{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36195,"status":"ok","timestamp":1680721623591,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":240},"id":"ykKrOq5l0OhQ","outputId":"764d4f09-8fcd-441c-b2d1-115768ee6685"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting EMD-signal\n","  Downloading EMD_signal-1.4.0-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.9/dist-packages (from EMD-signal) (1.10.1)\n","Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.9/dist-packages (from EMD-signal) (1.22.4)\n","Collecting pathos>=0.2.1\n","  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tqdm==4.64.*\n","  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ppft>=1.7.6.6\n","  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pox>=0.3.2\n","  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\n","Collecting multiprocess>=0.70.14\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill>=0.3.6\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tqdm, ppft, pox, dill, multiprocess, pathos, EMD-signal\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.65.0\n","    Uninstalling tqdm-4.65.0:\n","      Successfully uninstalled tqdm-4.65.0\n","Successfully installed EMD-signal-1.4.0 dill-0.3.6 multiprocess-0.70.14 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6 tqdm-4.64.1\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install EMD-signal"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6111,"status":"ok","timestamp":1680721639326,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":240},"id":"CHKJNHCA0aGF"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import time\n","import scipy\n","import scipy.io\n","from scipy.fft import fft\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim\n","from torch.utils import data\n","from torch.autograd import Variable\n","import pandas as pd"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1936,"status":"ok","timestamp":1680667768370,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":240},"id":"iNstVPvG0ata"},"outputs":[],"source":["import sys    \n","sys_path = '/content/drive/MyDrive/EMG-classification'\n","sys.path.append(sys_path)\n","from util import *\n","from dataloader import *"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6346,"status":"ok","timestamp":1680667777407,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":240},"id":"cljsEWYJ0nLT"},"outputs":[],"source":["# DataLoader\n","\n","record_data0501 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0501.npy')\n","record_data0502 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0502.npy')\n","record_data0503 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0503.npy')\n","record_data0505 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0505.npy')\n","record_data0506 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0506.npy')\n","labels0501 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0501.npy')\n","labels0502 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0502.npy')\n","labels0503 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0503.npy')\n","labels0505 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0505.npy')\n","labels0506 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0506.npy')\n","\n","signal0501 = record_data0501.flatten()\n","signal0502 = record_data0502.flatten()\n","signal0503 = record_data0503.flatten()\n","signal0505 = record_data0505.flatten()\n","signal0506 = record_data0506.flatten()\n","\n","train_label = labels0502\n","train_record_data = record_data0502\n","train_signal = signal0502\n","val_record_data, val_signal, val_label = record_data0501, signal0501, labels0501\n","\n","# train_label = np.concatenate((labels0502, labels0503, labels0505, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0502, record_data0503, record_data0505, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0502, signal0503, signal0505, signal0506))\n","# val_record_data, val_signal, val_label = record_data0501, signal0501, labels0501\n","# assert train_label.shape[0] == train_record_data.shape[0]\n","# print(\"train data:{}\\ntest data:{}\\n\".format(train_record_data.shape, record_data0501.shape))\n","\n","# # val - 0502\n","# train_label = np.concatenate((labels0501, labels0503, labels0505, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0503, record_data0505, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0503, signal0505, signal0506))\n","# val_record_data, val_signal, val_label = record_data0502, signal0502, labels0502\n","\n","# val - 0503\n","# train_label = np.concatenate((labels0501, labels0502, labels0505, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0502, record_data0505, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0502, signal0505, signal0506))\n","# val_record_data, val_signal, val_label = record_data0503, signal0503, labels0503\n","\n","# val 05\n","# train_label = np.concatenate((labels0501, labels0502, labels0503, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0502, record_data0503, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0502, signal0503, signal0506))\n","# val_record_data, val_signal, val_label = record_data0505, signal0505, labels0505\n","\n","# val06\n","# train_label = np.concatenate((labels0501, labels0502, labels0505, labels0503), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0502, record_data0505, record_data0503), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0502, signal0505, signal0503))\n","# val_record_data, val_signal, val_label = record_data0506, signal0506, labels0506"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBnuZHS6rWnL"},"outputs":[],"source":["def reference(signal,length_of_win,fft_length,start,end):\n","    fs = 1200\n","    win = s.get_window('hann', length_of_win) # the number of samples in the window// win:ndarray[length_of_win]\n","    norm_signal = []\n","    for i in range(start, end):\n","        [f, t, stft_signal] = s.spectrogram(signal[i*1200+40:(i+1)*1200], fs,\n","                                    window=win,\n","                                    nperseg=length_of_win,\n","                                    noverlap=0.8*length_of_win,\n","                                    nfft = fft_length)\n","        stft_signal = abs(stft_signal)\n","        norm_signal.append(stft_signal)\n","    norm_signal = np.hstack(norm_signal)\n","    reference_mean_norm = 10*np.log10(np.mean(norm_signal,axis = 1))\n","    reference_std_norm = np.std(norm_signal,axis = 1)\n","    return reference_mean_norm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4mZT-orVr21o"},"outputs":[],"source":["length_of_win,fft_length,start,end = 100,256,0,100\n","reference_0501 = reference(signal0501,length_of_win,fft_length,start,end)\n","reference_0502 = reference(signal0502,length_of_win,fft_length,start,end)\n","reference_0503 = reference(signal0503,length_of_win,fft_length,start,end)\n","reference_0505 = reference(signal0505,length_of_win,fft_length,start,end)\n","reference_0506 = reference(signal0506,length_of_win,fft_length,start,end)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":173,"status":"ok","timestamp":1680668431130,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":240},"id":"SMF_wyt30p2E"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, gamma=0, alpha=None, size_average=True):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        if isinstance(alpha,(float,int,float)): self.alpha = torch.Tensor([alpha,1-alpha])\n","        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n","        self.size_average = size_average\n","\n","    def forward(self, input, target):\n","        if input.dim()>2:\n","            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n","            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n","            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n","        target = target.view(-1,1)\n","\n","        logpt = F.log_softmax(input)\n","        logpt = logpt.gather(1,target)\n","        logpt = logpt.view(-1)\n","        pt = Variable(logpt.data.exp())\n","\n","        if self.alpha is not None:\n","            if self.alpha.type()!=input.data.type():\n","                self.alpha = self.alpha.type_as(input.data)\n","            at = self.alpha.gather(0,target.data.view(-1))\n","            logpt = logpt * Variable(at)\n","\n","        loss = -1 * (1-pt)**self.gamma * logpt\n","        if self.size_average: return loss.mean()\n","        else: return loss.sum()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":155,"status":"ok","timestamp":1680668436112,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":240},"id":"dkWm2y8K0qb9"},"outputs":[],"source":["class Netone(nn.Module):\n","    def __init__(self, num_classes, hidden_size, num_layers, middle_feature):\n","        super(Netone, self).__init__()\n","        self.num_classes = num_classes\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.bidirectional = False\n","        self.middle_feature = middle_feature\n","\n","        self.embedding = nn.Sequential(\n","            nn.Conv2d(1, 2, kernel_size=(3, 1), padding=(1, 0), stride=1),\n","            nn.ReLU(),\n","            nn.Conv2d(2, 4, kernel_size=(3, 1), padding=(1, 0), stride=1),\n","            nn.ReLU())\n","\n","        # self.embedding_dim = 1281\n","        # self.embedding_dim = 129*4\n","        self.embedding_dim = 51*4\n","        # h0 = 256 num_layers = 1\n","\n","        self.BiLSTM = nn.LSTM(input_size=self.embedding_dim,\n","                              hidden_size=self.hidden_size,\n","                              num_layers=self.num_layers,\n","                              dropout=0.2,\n","                              bidirectional=self.bidirectional)\n","\n","        self.MLP = nn.Sequential(\n","            nn.Linear(self.hidden_size, self.middle_feature),\n","            nn.ReLU(),\n","            nn.Linear(self.middle_feature, num_classes)\n","        )  # remove the mlp and generate the irritation state at each time step\n","\n","    def forward(self, datas):\n","        batch, f, t = datas.shape\n","        # print('input:', batch, f, t)# overall patient data = [1, 129, 54]\n","        # datas = datas.view(batch, 1, t, f)  # [N, C, H, W]\n","        datas = datas.reshape(batch, 1, t, f)\n","        embedded_datas = self.embedding(datas)\n","        # print('after conv:',embedded_datas.size()) # [1, 4, 56, 129]\n","        # embedded_datas = embedded_datas.permute(3, 0, 1, 2).view(f, batch, -1)\n","        embedded_datas = embedded_datas.permute(2, 0, 1, 3).reshape(t, batch, -1)\n","        # print('before lstm:',embedded_datas.size())\n","        out, _ = self.BiLSTM(embedded_datas)\n","        # print('after lstm:',out.size()) # [56, 1, 256]\n","        # out = out[-1, :, :]  # 20,512\n","        out = self.MLP(out.squeeze())\n","        # print('output shape:', out.shape)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99,"status":"ok","timestamp":1680460577796,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":240},"id":"A9vMmEUf2Lz0","outputId":"fc355257-80df-4c81-c9f0-9b02fec925fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["56\n","(56, 51)\n"]}],"source":["# FFT\n","testSignal0501 = signal0501[:1200]\n","# print(testSignal0501.shape)\n","window_length = 100\n","stride = 20\n","# Define a function to perform sliding FFT on the signal\n","def sliding_fft(signal, window_length, stride):\n","    # Calculate the number of windows\n","    num_windows = (len(signal) - window_length) // stride + 1\n","    print(num_windows)\n","\n","    # Initialize an array to store the FFT spectra\n","    spectra = np.zeros((num_windows, window_length // 2 + 1))\n","\n","    # Loop over the windows and calculate the FFT for each window\n","    for i in range(num_windows):\n","        start = i * stride\n","        end = start + window_length\n","        window = signal[start:end]\n","        window_spectrum = np.abs(fft(window)[:window_length // 2 + 1])\n","        spectra[i] = window_spectrum\n","\n","    return spectra\n","\n","# Process the signal with sliding FFT\n","spectra = sliding_fft(testSignal0501, window_length, stride)\n","print(spectra.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":157,"status":"ok","timestamp":1680668441772,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":240},"id":"DiNksd6GLS5l"},"outputs":[],"source":["def signal_fft(signal, window_length, stride):\n","    # Calculate the number of windows\n","    num_windows = (len(signal) - window_length) // stride + 1\n","\n","    # Initialize an array to store the FFT spectra\n","    spectra = np.zeros((num_windows, window_length // 2 + 1))\n","\n","    # Loop over the windows and calculate the FFT for each window\n","    for i in range(num_windows):\n","        start = i * stride\n","        end = start + window_length\n","        window = signal[start:end]\n","        window_spectrum = np.abs(fft(window)[:window_length // 2 + 1])\n","        spectra[i] = window_spectrum\n","\n","    return spectra"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"5KF9C2gHD9rb","outputId":"9f30f15d-5637-411e-ae98-3db63fe33f22","executionInfo":{"status":"error","timestamp":1680673364250,"user_tz":240,"elapsed":4919932,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","<ipython-input-8-cdcf9e11296b>:54: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n","  label_raw_tensor = torch.tensor(label_raw, dtype=torch.long)\n","<ipython-input-5-341bab4101f7>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  logpt = F.log_softmax(input)\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-cdcf9e11296b>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0;31m# print(train_raw.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mtrain_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0mlabel_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m       \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 319704 is out of bounds for axis 0 with size 319704"]}],"source":["window_length = 100\n","stride = 20\n","\n","train_raw = signal_fft(train_signal[:1200], window_length, stride)\n","num_windows = (len(train_signal) - window_length) // stride + 1\n","input_length, input_num = train_raw.shape # 56, 51\n","train_raw = train_raw.T.reshape(1,input_num,input_length) # [1, 51, 56]\n","train_label = np.repeat(train_label, 56)\n","# print(train_raw.shape)\n","\n","eps = 1\n","#set hidden size\n","hidden_size = 256\n","n_class = 9\n","learning_rate = 0.01\n","max_epochs = 20\n","middle_features = 128\n","model = Netone(num_classes=n_class, hidden_size=hidden_size, num_layers=1, middle_feature=middle_features) #num_classes, hidden_size, num_layers, bidirectional, middle_feature\n","#model.cuda()\n","# criterion = nn.CrossEntropyLoss()\n","criterion = FocalLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","train_acc = []\n","val_acc = []\n","\n","for epoch in range(max_epochs):\n","    correct_all = 0\n","    total_loss = 0\n","    train_length = 0\n","    predicted_train_csv = []\n","    real_train_csv = []\n","\n","    for batch_idx in range(input_length, num_windows - input_length):\n","      # sliding fft\n","      start = batch_idx*stride\n","      window = train_signal[start:(start+window_length)]\n","      tail = np.abs(fft(window)[:window_length // 2 + 1]) # (51,)\n","      train_raw = np.concatenate((train_raw[:, :, 1:], tail.reshape(1, -1, 1)), axis=2)\n","      # train_raw = train_raw.unsqueeze().reshape(0,2,1)\n","      # print(train_raw.shape)\n","      train_raw = torch.from_numpy(train_raw)\n","      label_raw = train_label[batch_idx-input_length+1]\n","      batch_x = Variable(train_raw.float())\n","      optimizer.zero_grad()\n","      output = model(batch_x)\n","      _, predicted_train = torch.max(output.data, 1)\n","      if label_raw==predicted_train[0]: correct_all += 1\n","      train_length += 1\n","\n","      predicted_train_csv.append(predicted_train[0].cpu().detach().numpy())\n","      real_train_csv.append(int(label_raw))\n","\n","      label_raw_tensor = torch.tensor(label_raw, dtype=torch.long)\n","      loss = criterion(output, label_raw_tensor)#.float().reshape(-1, 1)\n","      total_loss += loss\n","      loss.backward()\n","      optimizer.step()\n","\n","    print('\\n************************************************************************************************')\n","    print(\"Epoch {}/{}:, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n","        epoch+1,\n","        max_epochs,\n","        float(total_loss / train_length),\n","        float(optimizer.param_groups[0]['lr'])))\n","    print('train_acc:{}\\n'.format(correct_all/train_length))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5BwtBf0Chxw"},"outputs":[],"source":["# Use FFT\n","eps = 1\n","input_size = 129\n","#set hidden size\n","hidden_size = 256\n","n_class = 9\n","learning_rate = 0.1\n","max_epochs = 20\n","middle_features = 128\n","model = Netone(num_classes=n_class, hidden_size=hidden_size, num_layers=1, middle_feature=middle_features) #num_classes, hidden_size, num_layers, bidirectional, middle_feature\n","#model.cuda()\n","# criterion = nn.CrossEntropyLoss()\n","criterion = FocalLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","train_acc = []\n","val_acc = []\n","\n","for epoch in range(max_epochs):\n","    correct_all = 0\n","    total_loss = 0\n","    train_length = 0\n","    predicted_train_csv = []\n","    real_train_csv = []\n","\n","    for batch_idx in range(0,train_record_data.shape[0],eps):\n","        # tic = time.perf_counter()\n","        if batch_idx > train_record_data.shape[0]-eps: break\n","        train_eIMFs = train_signal[1200*batch_idx:1200*(batch_idx+eps)+1]\n","        train_raw = spectro(train_record_data[batch_idx:batch_idx+eps], train_eIMFs, 100, 256)\n","        train_raw = torch.from_numpy(train_raw)\n","        print(train_raw.shape)\n","        # train_filtered = train_raw[:, 5:, :]\n","        # print(\"shape after cutoff:{}\\n\".format(train_filtered.shape))\n","        label_raw = train_label[batch_idx:batch_idx+eps]\n","        # print(\"train_raw shape:{}\\n label_raw shape:{}\".format(train_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","        label = np.repeat(label_raw, train_raw.shape[-1])\n","        label = torch.from_numpy(label)\n","        # train_set = train_filtered.permute(0, 2, 1)\n","        # train_set = train_set.reshape(train_set.shape[0]*train_set.shape[1], -1)\n","        # print(\"train_set shape:{}\\nlabel shape:{}\\n\".format(train_set.shape, label.shape)) # [310284, 129]\n","\n","        # batch_x = torch.unsqueeze(train_raw, dim=0) # [1, 263736, 129]\n","        batch_x = Variable(train_raw.float())  # .cuda()\n","        batch_y = label.long()\n","\n","        optimizer.zero_grad()\n","        output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","        # toc = time.perf_counter()\n","        # print(f\"test epochs time in {toc - tic:0.4f} seconds\")\n","\n","        _, predicted_train = torch.max(output.data, 1)\n","        assert(len(predicted_train)==len(batch_y))\n","        correct_all += sum(batch_y.eq(predicted_train))\n","        train_length += len(batch_y)\n","\n","        predicted_train_csv.append(predicted_train.cpu().detach().numpy())\n","        real_train_csv.append(batch_y.cpu().detach().numpy())\n","\n","        loss = criterion(output, batch_y.squeeze())#.float().reshape(-1, 1)\n","        total_loss += loss\n","        loss.backward()\n","        optimizer.step()\n","\n","    np.save('/content/drive/MyDrive/EMG-classification/logs/fft/val01_train_pred_'+ str(correct_all / train_length) + '.npy', predicted_train_csv)\n","    np.save('/content/drive/MyDrive/EMG-classification/logs/fft/val01_train_real_'+ str(correct_all / train_length) + '.npy', real_train_csv)\n","\n","    print('\\n************************************************************************************************')\n","    print(\"Epoch {}/{}:, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n","        epoch+1,\n","        max_epochs,\n","        float(total_loss / train_length),\n","        float(optimizer.param_groups[0]['lr'])))\n","    print('train_acc:{}\\n'.format(correct_all/train_length))\n","\n","    if epoch%2==0:\n","        correct_all = 0\n","        predicted_val_csv = []\n","        real_val_csv = []\n","        val_length = 0\n","        for batch_idx in range(0,val_record_data.shape[0],eps):\n","            # tic = time.perf_counter()\n","            if batch_idx > val_record_data.shape[0]-eps: break\n","            # val_eIMFs = eemd.eemd(val_signal[1200*batch_idx:1200*(batch_idx+eps)+1])\n","            val_eIMFs = val_signal[1200*batch_idx:1200*(batch_idx+eps)+1]\n","            val_raw = spectro(val_record_data[batch_idx:batch_idx+eps], val_eIMFs, 100, 256)\n","            val_raw = torch.from_numpy(val_raw)\n","            # val_filtered = val_raw[:, 5:, :]\n","            label_raw = val_label[batch_idx:batch_idx+eps]\n","            # print(\"val_raw shape:{}\\n label_raw shape:{}\".format(val_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","            label = np.repeat(label_raw, val_raw.shape[-1])\n","            label = torch.from_numpy(label)\n","            # val_set = val_filtered.permute(0, 2, 1)\n","            # val_set = val_set.reshape(val_set.shape[0]*val_set.shape[1], -1)\n","            # print(\"val_set shape:{}\\nlabel shape:{}\\n\".format(val_set.shape, label.shape)) # [310284, 129]\n","\n","            # batch_x = torch.unsqueeze(val_raw, dim=0) # [1, 263736, 129]\n","            batch_x = Variable(val_raw.float())  # .cuda()\n","            batch_y = label.long()\n","\n","            output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","            # toc = time.perf_counter()\n","            # print(f\"Test time cost in {toc - tic:0.4f} seconds\")\n","\n","            _, predicted_val = torch.max(output.data, 1)\n","            # print(\"predicted_val shape:{}\\nbatch_y shape:{}\\n\".format(predicted_val.shape, batch_y.shape))\n","            # if len(predicted_val)!=len(batch_y): \n","            #   print(\"label shape:{}\\nval_raw shape:{}\\nlabel_raw shape:{}\".format(label.shape, val_raw.shape, label_raw.shape))\n","            correct_all += sum(batch_y.eq(predicted_val))\n","            val_length += len(batch_y)\n","            predicted_val_csv.append(predicted_val.cpu().detach().numpy())\n","            real_val_csv.append(batch_y.cpu().detach().numpy())\n","\n","        print('\\n************************************************************************************************')\n","        print(\"Epoch {}/{}:\\ntest_acc:{}\\n\".format(epoch+1, max_epochs, correct_all/val_length))\n","\n","        np.save('/content/drive/MyDrive/EMG-classification/logs/fft/val01_val_pred_'+ str(correct_all / val_length) + '.npy', predicted_val_csv)\n","        np.save('/content/drive/MyDrive/EMG-classification/logs/fft/val01_val_real_'+ str(correct_all / val_length) + '.npy', real_val_csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"EuluyZmb01-6","outputId":"1539e8e3-92f9-4e03-ddea-32bb23873bfc"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-5-341bab4101f7>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  logpt = F.log_softmax(input)\n"]},{"name":"stdout","output_type":"stream","text":["\n","************************************************************************************************\n","Epoch 1/20:, Train Loss 0.0071, Learning Rate 0.0010\n","train_acc:0.9093442559242249\n","\n","\n","************************************************************************************************\n","Epoch 1/20:\n","test_acc:0.6672337055206299\n","\n","\n","************************************************************************************************\n","Epoch 2/20:, Train Loss 0.0077, Learning Rate 0.0010\n","train_acc:0.9042321443557739\n","\n","\n","************************************************************************************************\n","Epoch 3/20:, Train Loss 0.0070, Learning Rate 0.0010\n","train_acc:0.9080585241317749\n","\n","\n","************************************************************************************************\n","Epoch 3/20:\n","test_acc:0.6672337055206299\n","\n","\n","************************************************************************************************\n","Epoch 4/20:, Train Loss 0.0077, Learning Rate 0.0010\n","train_acc:0.9004058241844177\n","\n","\n","************************************************************************************************\n","Epoch 5/20:, Train Loss 0.0072, Learning Rate 0.0010\n","train_acc:0.9019331336021423\n","\n","\n","************************************************************************************************\n","Epoch 5/20:\n","test_acc:0.6672337055206299\n","\n","\n","************************************************************************************************\n","Epoch 6/20:, Train Loss 0.0075, Learning Rate 0.0010\n","train_acc:0.905064582824707\n","\n","\n","************************************************************************************************\n","Epoch 7/20:, Train Loss 0.0084, Learning Rate 0.0010\n","train_acc:0.8822563290596008\n","\n","\n","************************************************************************************************\n","Epoch 7/20:\n","test_acc:0.6672337055206299\n","\n","\n","************************************************************************************************\n","Epoch 8/20:, Train Loss 0.0073, Learning Rate 0.0010\n","train_acc:0.9109805822372437\n","\n"]}],"source":["# input is added with window\n","eps = 1\n","input_size = 129\n","#set hidden size\n","hidden_size = 256\n","n_class = 9\n","learning_rate = 0.1\n","max_epochs = 20\n","middle_features = 128\n","model = Netone(num_classes=n_class, hidden_size=hidden_size, num_layers=1, middle_feature=middle_features) #num_classes, hidden_size, num_layers, bidirectional, middle_feature\n","#model.cuda()\n","# criterion = nn.CrossEntropyLoss()\n","criterion = FocalLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","train_acc = []\n","val_acc = []\n","\n","for epoch in range(max_epochs):\n","    correct_all = 0\n","    total_loss = 0\n","    train_length = 0\n","    predicted_train_csv = []\n","    real_train_csv = []\n","\n","    for batch_idx in range(0,train_record_data.shape[0],eps):\n","        # tic = time.perf_counter()\n","        if batch_idx > train_record_data.shape[0]-eps: break\n","        train_eIMFs = train_signal[1200*batch_idx:1200*(batch_idx+eps)+1]\n","        train_raw = spectro(train_record_data[batch_idx:batch_idx+eps], train_eIMFs, 100, 256)\n","        train_raw = torch.from_numpy(train_raw)\n","        # train_filtered = train_raw[:, 5:, :]\n","        # print(\"shape after cutoff:{}\\n\".format(train_filtered.shape))\n","        label_raw = train_label[batch_idx:batch_idx+eps]\n","        # print(\"train_raw shape:{}\\n label_raw shape:{}\".format(train_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","        label = np.repeat(label_raw, train_raw.shape[-1])\n","        label = torch.from_numpy(label)\n","        # train_set = train_filtered.permute(0, 2, 1)\n","        # train_set = train_set.reshape(train_set.shape[0]*train_set.shape[1], -1)\n","        # print(\"train_set shape:{}\\nlabel shape:{}\\n\".format(train_set.shape, label.shape)) # [310284, 129]\n","\n","        # batch_x = torch.unsqueeze(train_raw, dim=0) # [1, 263736, 129]\n","        batch_x = Variable(train_raw.float())  # .cuda()\n","        batch_y = label.long()\n","\n","        optimizer.zero_grad()\n","        output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","        # toc = time.perf_counter()\n","        # print(f\"test epochs time in {toc - tic:0.4f} seconds\")\n","\n","        _, predicted_train = torch.max(output.data, 1)\n","        assert(len(predicted_train)==len(batch_y))\n","        correct_all += sum(batch_y.eq(predicted_train))\n","        train_length += len(batch_y)\n","\n","        predicted_train_csv.append(predicted_train.cpu().detach().numpy())\n","        real_train_csv.append(batch_y.cpu().detach().numpy())\n","\n","        loss = criterion(output, batch_y.squeeze())#.float().reshape(-1, 1)\n","        total_loss += loss\n","        loss.backward()\n","        optimizer.step()\n","\n","    np.save('/content/drive/MyDrive/EMG-classification/logs/cnnlstm/val06_train_pred_'+ str(correct_all / train_length) + '.npy', predicted_train_csv)\n","    np.save('/content/drive/MyDrive/EMG-classification/logs/cnnlstm/val06_train_real_'+ str(correct_all / train_length) + '.npy', real_train_csv)\n","\n","    print('\\n************************************************************************************************')\n","    print(\"Epoch {}/{}:, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n","        epoch+1,\n","        max_epochs,\n","        float(total_loss / train_length),\n","        float(optimizer.param_groups[0]['lr'])))\n","    print('train_acc:{}\\n'.format(correct_all/train_length))\n","\n","    if epoch%2==0:\n","        correct_all = 0\n","        predicted_val_csv = []\n","        real_val_csv = []\n","        val_length = 0\n","        for batch_idx in range(0,val_record_data.shape[0],eps):\n","            # tic = time.perf_counter()\n","            if batch_idx > val_record_data.shape[0]-eps: break\n","            # val_eIMFs = eemd.eemd(val_signal[1200*batch_idx:1200*(batch_idx+eps)+1])\n","            val_eIMFs = val_signal[1200*batch_idx:1200*(batch_idx+eps)+1]\n","            val_raw = spectro(val_record_data[batch_idx:batch_idx+eps], val_eIMFs, 100, 256)\n","            val_raw = torch.from_numpy(val_raw)\n","            # val_filtered = val_raw[:, 5:, :]\n","            label_raw = val_label[batch_idx:batch_idx+eps]\n","            # print(\"val_raw shape:{}\\n label_raw shape:{}\".format(val_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","            label = np.repeat(label_raw, val_raw.shape[-1])\n","            label = torch.from_numpy(label)\n","            # val_set = val_filtered.permute(0, 2, 1)\n","            # val_set = val_set.reshape(val_set.shape[0]*val_set.shape[1], -1)\n","            # print(\"val_set shape:{}\\nlabel shape:{}\\n\".format(val_set.shape, label.shape)) # [310284, 129]\n","\n","            # batch_x = torch.unsqueeze(val_raw, dim=0) # [1, 263736, 129]\n","            batch_x = Variable(val_raw.float())  # .cuda()\n","            batch_y = label.long()\n","\n","            output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","            # toc = time.perf_counter()\n","            # print(f\"Test time cost in {toc - tic:0.4f} seconds\")\n","\n","            _, predicted_val = torch.max(output.data, 1)\n","            # print(\"predicted_val shape:{}\\nbatch_y shape:{}\\n\".format(predicted_val.shape, batch_y.shape))\n","            # if len(predicted_val)!=len(batch_y): \n","            #   print(\"label shape:{}\\nval_raw shape:{}\\nlabel_raw shape:{}\".format(label.shape, val_raw.shape, label_raw.shape))\n","            correct_all += sum(batch_y.eq(predicted_val))\n","            val_length += len(batch_y)\n","            predicted_val_csv.append(predicted_val.cpu().detach().numpy())\n","            real_val_csv.append(batch_y.cpu().detach().numpy())\n","\n","        print('\\n************************************************************************************************')\n","        print(\"Epoch {}/{}:\\ntest_acc:{}\\n\".format(epoch+1, max_epochs, correct_all/val_length))\n","\n","        np.save('/content/drive/MyDrive/EMG-classification/logs/cnnlstm/val06_val_pred_'+ str(correct_all / val_length) + '.npy', predicted_val_csv)\n","        np.save('/content/drive/MyDrive/EMG-classification/logs/cnnlstm/val06_val_real_'+ str(correct_all / val_length) + '.npy', real_val_csv)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPJD7sXBNKD3uE5iMBs3CdR"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}