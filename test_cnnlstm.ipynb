{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26365,"status":"ok","timestamp":1677086981794,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"ykKrOq5l0OhQ","outputId":"43748fff-2d99-4a6f-e027-91c29329d066"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting EMD-signal\n","  Downloading EMD_signal-1.4.0-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.12 in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (1.21.6)\n","Requirement already satisfied: tqdm==4.64.* in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (4.64.1)\n","Collecting pathos\u003e=0.2.1\n","  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy\u003e=0.19 in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (1.7.3)\n","Collecting ppft\u003e=1.7.6.6\n","  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pox\u003e=0.3.2\n","  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\n","Requirement already satisfied: dill\u003e=0.3.6 in /usr/local/lib/python3.8/dist-packages (from pathos\u003e=0.2.1-\u003eEMD-signal) (0.3.6)\n","Collecting multiprocess\u003e=0.70.14\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ppft, pox, multiprocess, pathos, EMD-signal\n","Successfully installed EMD-signal-1.4.0 multiprocess-0.70.14 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install EMD-signal"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4909,"status":"ok","timestamp":1677086986695,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"CHKJNHCA0aGF"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import time\n","import scipy\n","import scipy.io\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim\n","from torch.utils import data\n","from torch.autograd import Variable\n","import pandas as pd"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1760,"status":"ok","timestamp":1677086988445,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"iNstVPvG0ata"},"outputs":[],"source":["import sys    \n","sys_path = '/content/drive/MyDrive/EMG-classification'\n","sys.path.append(sys_path)\n","from util import *\n","from dataloader import *"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8895,"status":"ok","timestamp":1677086997330,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"cljsEWYJ0nLT"},"outputs":[],"source":["# DataLoader\n","\n","record_data0501 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0501.npy')\n","record_data0502 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0502.npy')\n","record_data0503 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0503.npy')\n","record_data0505 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0505.npy')\n","record_data0506 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0506.npy')\n","labels0501 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0501.npy')\n","labels0502 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0502.npy')\n","labels0503 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0503.npy')\n","labels0505 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0505.npy')\n","labels0506 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0506.npy')\n","\n","signal0501 = record_data0501.flatten()\n","signal0502 = record_data0502.flatten()\n","signal0503 = record_data0503.flatten()\n","signal0505 = record_data0505.flatten()\n","signal0506 = record_data0506.flatten()\n","\n","# train_label = np.concatenate((labels0502, labels0503, labels0505, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0502, record_data0503, record_data0505, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0502, signal0503, signal0505, signal0506))\n","# val_record_data, val_signal, val_label = record_data0501, signal0501, labels0501\n","# assert train_label.shape[0] == train_record_data.shape[0]\n","# print(\"train data:{}\\ntest data:{}\\n\".format(train_record_data.shape, record_data0501.shape))\n","\n","# # val - 0502\n","# train_label = np.concatenate((labels0501, labels0503, labels0505, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0503, record_data0505, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0503, signal0505, signal0506))\n","# val_record_data, val_signal, val_label = record_data0502, signal0502, labels0502\n","\n","# val - 0503\n","# train_label = np.concatenate((labels0501, labels0502, labels0505, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0502, record_data0505, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0502, signal0505, signal0506))\n","# val_record_data, val_signal, val_label = record_data0503, signal0503, labels0503\n","\n","#val 05\n","# train_label = np.concatenate((labels0501, labels0502, labels0503, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0502, record_data0503, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0502, signal0503, signal0506))\n","# val_record_data, val_signal, val_label = record_data0505, signal0505, labels0505\n","\n","# val06\n","# train_label = np.concatenate((labels0501, labels0502, labels0505, labels0503), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0502, record_data0505, record_data0503), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0502, signal0505, signal0503))\n","# val_record_data, val_signal, val_label = record_data0506, signal0506, labels0506\n","\n","train_label = np.concatenate((labels0501, labels0503, labels0506), axis=0)\n","train_record_data = np.concatenate((record_data0501, record_data0503, record_data0506), axis=0)\n","train_signal = np.concatenate((signal0501, signal0503, signal0506))\n","val_record_data, val_signal, val_label = record_data0505, signal0505, labels0505"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1677086997331,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"SMF_wyt30p2E"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, gamma=0, alpha=None, size_average=True):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        if isinstance(alpha,(float,int,float)): self.alpha = torch.Tensor([alpha,1-alpha])\n","        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n","        self.size_average = size_average\n","\n","    def forward(self, input, target):\n","        if input.dim()\u003e2:\n","            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W =\u003e N,C,H*W\n","            input = input.transpose(1,2)    # N,C,H*W =\u003e N,H*W,C\n","            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C =\u003e N*H*W,C\n","        target = target.view(-1,1)\n","\n","        logpt = F.log_softmax(input)\n","        logpt = logpt.gather(1,target)\n","        logpt = logpt.view(-1)\n","        pt = Variable(logpt.data.exp())\n","\n","        if self.alpha is not None:\n","            if self.alpha.type()!=input.data.type():\n","                self.alpha = self.alpha.type_as(input.data)\n","            at = self.alpha.gather(0,target.data.view(-1))\n","            logpt = logpt * Variable(at)\n","\n","        loss = -1 * (1-pt)**self.gamma * logpt\n","        if self.size_average: return loss.mean()\n","        else: return loss.sum()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1677086997331,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"dkWm2y8K0qb9"},"outputs":[],"source":["class Netone(nn.Module):\n","    def __init__(self, num_classes, hidden_size, num_layers, middle_feature):\n","        super(Netone, self).__init__()\n","        self.num_classes = num_classes\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.bidirectional = False\n","        self.middle_feature = middle_feature\n","\n","        self.embedding = nn.Sequential(\n","            nn.Conv2d(1, 2, kernel_size=(3, 1), padding=(1, 0), stride=1),\n","            nn.ReLU(),\n","            nn.Conv2d(2, 4, kernel_size=(3, 1), padding=(1, 0), stride=1),\n","            nn.ReLU())\n","\n","        # self.embedding_dim = 1281\n","        self.embedding_dim = 129*4\n","        # h0 = 256 num_layers = 1\n","\n","        self.BiLSTM = nn.LSTM(input_size=self.embedding_dim,\n","                              hidden_size=self.hidden_size,\n","                              num_layers=self.num_layers,\n","                              dropout=0.2,\n","                              bidirectional=self.bidirectional)\n","\n","        self.MLP = nn.Sequential(\n","            nn.Linear(self.hidden_size, self.middle_feature),\n","            nn.ReLU(),\n","            nn.Linear(self.middle_feature, num_classes)\n","        )  # remove the mlp and generate the irritation state at each time step\n","\n","    def forward(self, datas):\n","        batch, f, t = datas.shape\n","        # print('input:', batch, f, t)# overall patient data = [1, 129, 54]\n","        # datas = datas.view(batch, 1, t, f)  # [N, C, H, W]\n","        datas = datas.reshape(batch, 1, t, f)\n","        embedded_datas = self.embedding(datas)\n","        # print('after conv:',embedded_datas.size()) # [1, 4, 56, 129]\n","        # embedded_datas = embedded_datas.permute(3, 0, 1, 2).view(f, batch, -1)\n","        embedded_datas = embedded_datas.permute(2, 0, 1, 3).reshape(t, batch, -1)\n","        # print('before lstm:',embedded_datas.size())\n","        out, _ = self.BiLSTM(embedded_datas)\n","        # print('after lstm:',out.size()) # [56, 1, 256]\n","        # out = out[-1, :, :]  # 20,512\n","        out = self.MLP(out.squeeze())\n","        # print('output shape:', out.shape)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"EuluyZmb01-6"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-5-341bab4101f7\u003e:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  logpt = F.log_softmax(input)\n"]},{"name":"stdout","output_type":"stream","text":["\n","************************************************************************************************\n","Epoch 1/20:, Train Loss 0.0154, Learning Rate 0.0010\n","train_acc:0.7428754568099976\n","\n","\n","************************************************************************************************\n","Epoch 1/20:\n","test_acc:0.19928421080112457\n","\n","\n","************************************************************************************************\n","Epoch 2/20:, Train Loss 0.0175, Learning Rate 0.0010\n","train_acc:0.7099743485450745\n","\n","\n","************************************************************************************************\n","Epoch 3/20:, Train Loss 0.0177, Learning Rate 0.0010\n","train_acc:0.7100266814231873\n","\n","\n","************************************************************************************************\n","Epoch 3/20:\n","test_acc:0.19928421080112457\n","\n","\n","************************************************************************************************\n","Epoch 4/20:, Train Loss 0.0178, Learning Rate 0.0010\n","train_acc:0.7100266814231873\n","\n"]}],"source":["# input is added with window\n","eps = 1\n","input_size = 129\n","#set hidden size\n","hidden_size = 256\n","n_class = 9\n","learning_rate = 0.1\n","max_epochs = 20\n","middle_features = 128\n","model = Netone(num_classes=n_class, hidden_size=hidden_size, num_layers=1, middle_feature=middle_features) #num_classes, hidden_size, num_layers, bidirectional, middle_feature\n","#model.cuda()\n","# criterion = nn.CrossEntropyLoss()\n","criterion = FocalLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","train_acc = []\n","val_acc = []\n","\n","for epoch in range(max_epochs):\n","    correct_all = 0\n","    total_loss = 0\n","    train_length = 0\n","    predicted_train_csv = []\n","    real_train_csv = []\n","\n","    for batch_idx in range(0,train_record_data.shape[0],eps):\n","        # tic = time.perf_counter()\n","        if batch_idx \u003e train_record_data.shape[0]-eps: break\n","        train_eIMFs = train_signal[1200*batch_idx:1200*(batch_idx+eps)+1]\n","        train_raw = spectro(train_record_data[batch_idx:batch_idx+eps], train_eIMFs, 100, 256)\n","        train_raw = torch.from_numpy(train_raw)\n","        # train_filtered = train_raw[:, 5:, :]\n","        # print(\"shape after cutoff:{}\\n\".format(train_filtered.shape))\n","        label_raw = train_label[batch_idx:batch_idx+eps]\n","        # print(\"train_raw shape:{}\\n label_raw shape:{}\".format(train_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","        label = np.repeat(label_raw, train_raw.shape[-1])\n","        label = torch.from_numpy(label)\n","        # train_set = train_filtered.permute(0, 2, 1)\n","        # train_set = train_set.reshape(train_set.shape[0]*train_set.shape[1], -1)\n","        # print(\"train_set shape:{}\\nlabel shape:{}\\n\".format(train_set.shape, label.shape)) # [310284, 129]\n","\n","        # batch_x = torch.unsqueeze(train_raw, dim=0) # [1, 263736, 129]\n","        batch_x = Variable(train_raw.float())  # .cuda()\n","        batch_y = label.long()\n","\n","        optimizer.zero_grad()\n","        output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","        # toc = time.perf_counter()\n","        # print(f\"test epochs time in {toc - tic:0.4f} seconds\")\n","\n","        _, predicted_train = torch.max(output.data, 1)\n","        assert(len(predicted_train)==len(batch_y))\n","        correct_all += sum(batch_y.eq(predicted_train))\n","        train_length += len(batch_y)\n","\n","        predicted_train_csv.append(predicted_train.cpu().detach().numpy())\n","        real_train_csv.append(batch_y.cpu().detach().numpy())\n","\n","        loss = criterion(output, batch_y.squeeze())#.float().reshape(-1, 1)\n","        total_loss += loss\n","        loss.backward()\n","        optimizer.step()\n","\n","    np.save('/content/drive/MyDrive/EMG-classification/logs/cnnlstm/val05_train_pred_'+ str(correct_all / train_length) + '.npy', predicted_train_csv)\n","    np.save('/content/drive/MyDrive/EMG-classification/logs/cnnlstm/val05_train_real_'+ str(correct_all / train_length) + '.npy', real_train_csv)\n","\n","    print('\\n************************************************************************************************')\n","    print(\"Epoch {}/{}:, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n","        epoch+1,\n","        max_epochs,\n","        float(total_loss / train_length),\n","        float(optimizer.param_groups[0]['lr'])))\n","    print('train_acc:{}\\n'.format(correct_all/train_length))\n","\n","    if epoch%2==0:\n","        correct_all = 0\n","        predicted_val_csv = []\n","        real_val_csv = []\n","        val_length = 0\n","        for batch_idx in range(0,val_record_data.shape[0],eps):\n","            # tic = time.perf_counter()\n","            if batch_idx \u003e val_record_data.shape[0]-eps: break\n","            # val_eIMFs = eemd.eemd(val_signal[1200*batch_idx:1200*(batch_idx+eps)+1])\n","            val_eIMFs = val_signal[1200*batch_idx:1200*(batch_idx+eps)+1]\n","            val_raw = spectro(val_record_data[batch_idx:batch_idx+eps], val_eIMFs, 100, 256)\n","            val_raw = torch.from_numpy(val_raw)\n","            # val_filtered = val_raw[:, 5:, :]\n","            label_raw = val_label[batch_idx:batch_idx+eps]\n","            # print(\"val_raw shape:{}\\n label_raw shape:{}\".format(val_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","            label = np.repeat(label_raw, val_raw.shape[-1])\n","            label = torch.from_numpy(label)\n","            # val_set = val_filtered.permute(0, 2, 1)\n","            # val_set = val_set.reshape(val_set.shape[0]*val_set.shape[1], -1)\n","            # print(\"val_set shape:{}\\nlabel shape:{}\\n\".format(val_set.shape, label.shape)) # [310284, 129]\n","\n","            # batch_x = torch.unsqueeze(val_raw, dim=0) # [1, 263736, 129]\n","            batch_x = Variable(val_raw.float())  # .cuda()\n","            batch_y = label.long()\n","\n","            output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","            # toc = time.perf_counter()\n","            # print(f\"Test time cost in {toc - tic:0.4f} seconds\")\n","\n","            _, predicted_val = torch.max(output.data, 1)\n","            # print(\"predicted_val shape:{}\\nbatch_y shape:{}\\n\".format(predicted_val.shape, batch_y.shape))\n","            # if len(predicted_val)!=len(batch_y): \n","            #   print(\"label shape:{}\\nval_raw shape:{}\\nlabel_raw shape:{}\".format(label.shape, val_raw.shape, label_raw.shape))\n","            correct_all += sum(batch_y.eq(predicted_val))\n","            val_length += len(batch_y)\n","            predicted_val_csv.append(predicted_val.cpu().detach().numpy())\n","            real_val_csv.append(batch_y.cpu().detach().numpy())\n","\n","        print('\\n************************************************************************************************')\n","        print(\"Epoch {}/{}:\\ntest_acc:{}\\n\".format(epoch+1, max_epochs, correct_all/val_length))\n","\n","        np.save('/content/drive/MyDrive/EMG-classification/logs/cnnlstm/val05_val_pred_'+ str(correct_all / val_length) + '.npy', predicted_val_csv)\n","        np.save('/content/drive/MyDrive/EMG-classification/logs/cnnlstm/val05_val_real_'+ str(correct_all / val_length) + '.npy', real_val_csv)"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyPIjPvab0GbFBjYMDOjR+mo","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}