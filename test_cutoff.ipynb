{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3964,"status":"ok","timestamp":1676043681863,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"rTDdE6rR1kEP","outputId":"9d43196b-8a4b-425e-9841-be0b0046955a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: EMD-signal in /usr/local/lib/python3.8/dist-packages (1.4.0)\n","Requirement already satisfied: pathos\u003e=0.2.1 in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (0.3.0)\n","Requirement already satisfied: scipy\u003e=0.19 in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (1.7.3)\n","Requirement already satisfied: numpy\u003e=1.12 in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (1.21.6)\n","Requirement already satisfied: tqdm==4.64.* in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (4.64.1)\n","Requirement already satisfied: pox\u003e=0.3.2 in /usr/local/lib/python3.8/dist-packages (from pathos\u003e=0.2.1-\u003eEMD-signal) (0.3.2)\n","Requirement already satisfied: ppft\u003e=1.7.6.6 in /usr/local/lib/python3.8/dist-packages (from pathos\u003e=0.2.1-\u003eEMD-signal) (1.7.6.6)\n","Requirement already satisfied: multiprocess\u003e=0.70.14 in /usr/local/lib/python3.8/dist-packages (from pathos\u003e=0.2.1-\u003eEMD-signal) (0.70.14)\n","Requirement already satisfied: dill\u003e=0.3.6 in /usr/local/lib/python3.8/dist-packages (from pathos\u003e=0.2.1-\u003eEMD-signal) (0.3.6)\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install EMD-signal"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5056,"status":"ok","timestamp":1676043686914,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"wCADPK3U1tHa"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import time\n","import scipy\n","import scipy.io\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim\n","from torch.utils import data\n","from torch.autograd import Variable\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import sys    \n","sys_path = '/content/drive/MyDrive/EMG-classification'\n","sys.path.append(sys_path)\n","from util import *\n","from dataloader import *\n","from model import *"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5753,"status":"ok","timestamp":1676043692648,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"Oc2ZMy001yDj"},"outputs":[],"source":["# DataLoader\n","\n","record_data0501 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0501.npy')\n","record_data0502 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0502.npy')\n","record_data0503 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0503.npy')\n","record_data0505 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0505.npy')\n","record_data0506 = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0506.npy')\n","labels0501 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0501.npy')\n","labels0502 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0502.npy')\n","labels0503 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0503.npy')\n","labels0505 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0505.npy')\n","labels0506 = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0506.npy')\n","\n","signal0501 = record_data0501.flatten()\n","signal0502 = record_data0502.flatten()\n","signal0503 = record_data0503.flatten()\n","signal0505 = record_data0505.flatten()\n","signal0506 = record_data0506.flatten()\n","\n","# train_label = np.concatenate((labels0502, labels0503, labels0505, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0502, record_data0503, record_data0505, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0502, signal0503, signal0505, signal0506))\n","# val_record_data, val_signal, val_label = record_data0501, signal0501, labels0501\n","# assert train_label.shape[0] == train_record_data.shape[0]\n","# print(\"train data:{}\\ntest data:{}\\n\".format(train_record_data.shape, record_data0501.shape))\n","\n","# # val - 0502\n","# train_label = np.concatenate((labels0501, labels0503, labels0505, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0503, record_data0505, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0503, signal0505, signal0506))\n","# val_record_data, val_signal, val_label = record_data0502, signal0502, labels0502\n","\n","# val - 0503\n","# train_label = np.concatenate((labels0501, labels0502, labels0505, labels0506), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0502, record_data0505, record_data0506), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0502, signal0505, signal0506))\n","# val_record_data, val_signal, val_label = record_data0503, signal0503, labels0503\n","\n","#val 05\n","train_label = np.concatenate((labels0501, labels0502, labels0503, labels0506), axis=0)\n","train_record_data = np.concatenate((record_data0501, record_data0502, record_data0503, record_data0506), axis=0)\n","train_signal = np.concatenate((signal0501, signal0502, signal0503, signal0506))\n","val_record_data, val_signal, val_label = record_data0505, signal0505, labels0505\n","\n","# val06\n","# train_label = np.concatenate((labels0501, labels0502, labels0505, labels0503), axis=0)\n","# train_record_data = np.concatenate((record_data0501, record_data0502, record_data0505, record_data0503), axis=0)\n","# train_signal = np.concatenate((signal0501, signal0502, signal0505, signal0503))\n","# val_record_data, val_signal, val_label = record_data0506, signal0506, labels0506"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1676043692649,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"},"user_tz":300},"id":"AQfdMAyFFJZj"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, gamma=0, alpha=None, size_average=True):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        if isinstance(alpha,(float,int,float)): self.alpha = torch.Tensor([alpha,1-alpha])\n","        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n","        self.size_average = size_average\n","\n","    def forward(self, input, target):\n","        if input.dim()\u003e2:\n","            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W =\u003e N,C,H*W\n","            input = input.transpose(1,2)    # N,C,H*W =\u003e N,H*W,C\n","            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C =\u003e N*H*W,C\n","        target = target.view(-1,1)\n","\n","        logpt = F.log_softmax(input)\n","        logpt = logpt.gather(1,target)\n","        logpt = logpt.view(-1)\n","        pt = Variable(logpt.data.exp())\n","\n","        if self.alpha is not None:\n","            if self.alpha.type()!=input.data.type():\n","                self.alpha = self.alpha.type_as(input.data)\n","            at = self.alpha.gather(0,target.data.view(-1))\n","            logpt = logpt * Variable(at)\n","\n","        loss = -1 * (1-pt)**self.gamma * logpt\n","        if self.size_average: return loss.mean()\n","        else: return loss.sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"lS9gxxPN16Pb"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-4-341bab4101f7\u003e:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  logpt = F.log_softmax(input)\n"]},{"name":"stdout","output_type":"stream","text":["\n","************************************************************************************************\n","Epoch 1/20:, Train Loss 0.0015, Learning Rate 0.0010\n","train_acc:0.7422794103622437\n","\n","\n","************************************************************************************************\n","Epoch 1/20:\n","test_acc:0.19837133586406708\n","\n","\n","************************************************************************************************\n","Epoch 2/20:, Train Loss 0.0016, Learning Rate 0.0010\n","train_acc:0.6995172500610352\n","\n","\n","************************************************************************************************\n","Epoch 3/20:, Train Loss 0.0016, Learning Rate 0.0010\n","train_acc:0.6592285633087158\n","\n","\n","************************************************************************************************\n","Epoch 3/20:\n","test_acc:0.19837133586406708\n","\n","\n","************************************************************************************************\n","Epoch 4/20:, Train Loss 0.0017, Learning Rate 0.0010\n","train_acc:0.710651695728302\n","\n"]}],"source":["# input is added with window\n","eps = 10\n","input_size = 124\n","#set hidden size\n","hidden_size = 124\n","n_class = 9\n","learning_rate = 0.1\n","max_epochs = 20\n","middle_features = 128\n","model = Netone(num_classes=n_class, hidden_size=hidden_size, num_layers=1, middle_feature=middle_features) #num_classes, hidden_size, num_layers, bidirectional, middle_feature\n","#model.cuda()\n","# criterion = nn.CrossEntropyLoss()\n","criterion = FocalLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","train_acc = []\n","val_acc = []\n","\n","for epoch in range(max_epochs):\n","    correct_all = 0\n","    total_loss = 0\n","    train_length = 0\n","    predicted_train_csv = []\n","    real_train_csv = []\n","\n","    for batch_idx in range(0,train_record_data.shape[0],eps):\n","        # tic = time.perf_counter()\n","        if batch_idx \u003e train_record_data.shape[0]-eps: break\n","        train_eIMFs = train_signal[1200*batch_idx:1200*(batch_idx+eps)+1]\n","        train_raw = spectro(train_record_data[batch_idx:batch_idx+eps], train_eIMFs, 100, 256)\n","        train_raw = torch.from_numpy(train_raw)\n","        train_filtered = train_raw[:, 5:, :]\n","        # print(\"shape after cutoff:{}\\n\".format(train_filtered.shape))\n","        label_raw = train_label[batch_idx:batch_idx+eps]\n","        # print(\"train_raw shape:{}\\n label_raw shape:{}\".format(train_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","        label = np.repeat(label_raw, train_filtered.shape[-1])\n","        label = torch.from_numpy(label)\n","        train_set = train_filtered.permute(0, 2, 1)\n","        train_set = train_set.reshape(train_set.shape[0]*train_set.shape[1], -1)\n","        # print(\"train_set shape:{}\\nlabel shape:{}\\n\".format(train_set.shape, label.shape)) # [310284, 129]\n","\n","        batch_x = torch.unsqueeze(train_set, dim=0) # [1, 263736, 129]\n","        batch_x = Variable(batch_x.float())  # .cuda()\n","        batch_y = label.long()\n","\n","        optimizer.zero_grad()\n","        output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","        # toc = time.perf_counter()\n","        # print(f\"test epochs time in {toc - tic:0.4f} seconds\")\n","\n","        _, predicted_train = torch.max(output.data, 1)\n","        assert(len(predicted_train)==len(batch_y))\n","        correct_all += sum(batch_y.eq(predicted_train))\n","        train_length += len(batch_y)\n","\n","        predicted_train_csv.append(predicted_train.cpu().detach().numpy())\n","        real_train_csv.append(batch_y.cpu().detach().numpy())\n","\n","        loss = criterion(output, batch_y.squeeze())#.float().reshape(-1, 1)\n","        total_loss += loss\n","        loss.backward()\n","        optimizer.step()\n","\n","    np.save('/content/drive/MyDrive/EMG-classification/logs/focalLoss_cutoff5/val05_train_pred_'+ str(correct_all / train_length) + '.npy', predicted_train_csv)\n","    np.save('/content/drive/MyDrive/EMG-classification/logs/focalLoss_cutoff5/val05_train_real_'+ str(correct_all / train_length) + '.npy', real_train_csv)\n","\n","    print('\\n************************************************************************************************')\n","    print(\"Epoch {}/{}:, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n","        epoch+1,\n","        max_epochs,\n","        float(total_loss / train_length),\n","        float(optimizer.param_groups[0]['lr'])))\n","    print('train_acc:{}\\n'.format(correct_all/train_length))\n","\n","    if epoch%2==0:\n","        correct_all = 0\n","        predicted_val_csv = []\n","        real_val_csv = []\n","        val_length = 0\n","        for batch_idx in range(0,val_record_data.shape[0],eps):\n","            # tic = time.perf_counter()\n","            if batch_idx \u003e val_record_data.shape[0]-eps: break\n","            # val_eIMFs = eemd.eemd(val_signal[1200*batch_idx:1200*(batch_idx+eps)+1])\n","            val_eIMFs = val_signal[1200*batch_idx:1200*(batch_idx+eps)+1]\n","            val_raw = spectro(val_record_data[batch_idx:batch_idx+eps], val_eIMFs, 100, 256)\n","            val_raw = torch.from_numpy(val_raw)\n","            val_filtered = val_raw[:, 5:, :]\n","            label_raw = val_label[batch_idx:batch_idx+eps]\n","            # print(\"val_raw shape:{}\\n label_raw shape:{}\".format(val_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","            label = np.repeat(label_raw, val_filtered.shape[-1])\n","            label = torch.from_numpy(label)\n","            val_set = val_filtered.permute(0, 2, 1)\n","            val_set = val_set.reshape(val_set.shape[0]*val_set.shape[1], -1)\n","            # print(\"val_set shape:{}\\nlabel shape:{}\\n\".format(val_set.shape, label.shape)) # [310284, 129]\n","\n","            batch_x = torch.unsqueeze(val_set, dim=0) # [1, 263736, 129]\n","            batch_x = Variable(batch_x.float())  # .cuda()\n","            batch_y = label.long()\n","\n","            output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","            # toc = time.perf_counter()\n","            # print(f\"Test time cost in {toc - tic:0.4f} seconds\")\n","\n","            _, predicted_val = torch.max(output.data, 1)\n","            # print(\"predicted_val shape:{}\\nbatch_y shape:{}\\n\".format(predicted_val.shape, batch_y.shape))\n","            # if len(predicted_val)!=len(batch_y): \n","            #   print(\"label shape:{}\\nval_raw shape:{}\\nlabel_raw shape:{}\".format(label.shape, val_raw.shape, label_raw.shape))\n","            correct_all += sum(batch_y.eq(predicted_val))\n","            val_length += len(batch_y)\n","            predicted_val_csv.append(predicted_val.cpu().detach().numpy())\n","            real_val_csv.append(batch_y.cpu().detach().numpy())\n","\n","        print('\\n************************************************************************************************')\n","        print(\"Epoch {}/{}:\\ntest_acc:{}\\n\".format(epoch+1, max_epochs, correct_all/val_length))\n","\n","        np.save('/content/drive/MyDrive/EMG-classification/logs/focalLoss_cutoff5/val05_val_pred_'+ str(correct_all / val_length) + '.npy', predicted_val_csv)\n","        np.save('/content/drive/MyDrive/EMG-classification/logs/focalLoss_cutoff5/val05_val_real_'+ str(correct_all / val_length) + '.npy', real_val_csv)"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyOXVuAxuzO+1Hst8ZEZLwzF","machine_shape":"hm","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}