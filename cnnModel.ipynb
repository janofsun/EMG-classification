{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPuyYZgmX2XoJouf+6lqgcd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ERAGP3byK2y0","executionInfo":{"status":"ok","timestamp":1677038422229,"user_tz":300,"elapsed":25924,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"}},"outputId":"0db7e471-3c43-41bc-f19f-b7869ce7bee3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting EMD-signal\n","  Downloading EMD_signal-1.4.0-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm==4.64.* in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (4.64.1)\n","Collecting pathos>=0.2.1\n","  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (1.21.6)\n","Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.8/dist-packages (from EMD-signal) (1.7.3)\n","Collecting ppft>=1.7.6.6\n","  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess>=0.70.14\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from pathos>=0.2.1->EMD-signal) (0.3.6)\n","Collecting pox>=0.3.2\n","  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\n","Installing collected packages: ppft, pox, multiprocess, pathos, EMD-signal\n","Successfully installed EMD-signal-1.4.0 multiprocess-0.70.14 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install EMD-signal"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import time\n","import scipy\n","import scipy.io\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim\n","from torch.utils import data\n","from torch.autograd import Variable\n","import pandas as pd\n","from PyEMD import EEMD"],"metadata":{"id":"TSTrPt7DLAGg","executionInfo":{"status":"ok","timestamp":1677038484053,"user_tz":300,"elapsed":4642,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import sys    \n","sys_path = '/content/drive/MyDrive/EMG-classification'\n","sys.path.append(sys_path)\n","from util import *\n","from dataloader import *"],"metadata":{"id":"UuPj2DemLLFD","executionInfo":{"status":"ok","timestamp":1677038486986,"user_tz":300,"elapsed":1426,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# DataLoader\n","\n","train_record_data = np.load('/content/drive/MyDrive/EMG-classification/dataset/rawdata/record_data0501.npy')\n","train_label = np.load('/content/drive/MyDrive/EMG-classification/dataset/label/label0501.npy')\n","\n","train_signal = train_record_data.flatten()\n","print(\"train data:{}\\n\".format(train_record_data.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c23lgETkLRY8","executionInfo":{"status":"ok","timestamp":1677038583087,"user_tz":300,"elapsed":142,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"}},"outputId":"9bd3fa3a-66bf-43d2-9ba0-09d07cd0893e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["train data:(5746, 1200)\n","\n"]}]},{"cell_type":"code","source":["class Netone(nn.Module):\n","    def __init__(self, num_classes, hidden_size, num_layers, middle_feature):\n","        super(Netone, self).__init__()\n","        self.num_classes = num_classes\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.bidirectional = False\n","        self.middle_feature = middle_feature\n","\n","        self.embedding = nn.Sequential(\n","            nn.Conv2d(1, 2, kernel_size=(3, 1), padding=(1, 0), stride=1),\n","            nn.ReLU(),\n","            nn.Conv2d(2, 4, kernel_size=(3, 1), padding=(1, 0), stride=1),\n","            nn.ReLU())\n","\n","        # self.embedding_dim = 1281\n","        self.embedding_dim = 129*4\n","        # h0 = 256 num_layers = 1\n","\n","        self.BiLSTM = nn.LSTM(input_size=self.embedding_dim,\n","                              hidden_size=self.hidden_size,\n","                              num_layers=self.num_layers,\n","                              dropout=0.2,\n","                              bidirectional=self.bidirectional)\n","\n","        self.MLP = nn.Sequential(\n","            nn.Linear(self.hidden_size, self.middle_feature),\n","            nn.ReLU(),\n","            nn.Linear(self.middle_feature, num_classes)\n","        )  # remove the mlp and generate the irritation state at each time step\n","\n","    def forward(self, datas):\n","        batch, f, t = datas.shape\n","        # print('input:', batch, f, t)# overall patient data = [1, 129, 54]\n","        # datas = datas.view(batch, 1, t, f)  # [N, C, H, W]\n","        datas = datas.reshape(batch, 1, t, f)\n","        embedded_datas = self.embedding(datas)\n","        # print('after conv:',embedded_datas.size()) # [1, 4, 56, 129]\n","        # embedded_datas = embedded_datas.permute(3, 0, 1, 2).view(f, batch, -1)\n","        embedded_datas = embedded_datas.permute(2, 0, 1, 3).reshape(t, batch, -1)\n","        # print('before lstm:',embedded_datas.size())\n","        out, _ = self.BiLSTM(embedded_datas)\n","        # print('after lstm:',out.size()) # [56, 1, 256]\n","        # out = out[-1, :, :]  # 20,512\n","        out = self.MLP(out.squeeze())\n","        # print('output shape:', out.shape)\n","        return out"],"metadata":{"id":"XNsgP_CRMlyu","executionInfo":{"status":"ok","timestamp":1677041609751,"user_tz":300,"elapsed":137,"user":{"displayName":"Jade Sun","userId":"01564590847962594099"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["eps = 1\n","input_size = 129\n","#set hidden size\n","hidden_size = 256\n","n_class = 9\n","learning_rate = 0.01\n","max_epochs = 20\n","middle_features = 128\n","model = Netone(num_classes=n_class, hidden_size=hidden_size, num_layers=1, middle_feature=middle_features) \n","#num_classes, hidden_size, num_layers, bidirectional, middle_feature\n","#model.cuda()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","train_acc = []\n","val_acc = []\n","\n","for epoch in range(max_epochs):\n","    correct_all = 0\n","    total_loss = 0\n","    train_length = 0\n","    predicted_train_csv = []\n","    real_train_csv = []\n","\n","    for batch_idx in range(0,train_record_data.shape[0],eps):\n","        train_eIMFs = train_signal[1200*batch_idx:1200*(batch_idx+eps)+1]\n","        train_raw = spectro(train_record_data[batch_idx:batch_idx+eps], train_eIMFs, 100, 256)\n","        train_raw = torch.from_numpy(train_raw)\n","        label_raw = train_label[batch_idx:batch_idx+eps]\n","        # print(\"train_raw shape:{}\\n label_raw shape:{}\".format(train_raw.shape, label_raw.shape)) # (1, 129, 56)\n","\n","        label = np.repeat(label_raw, train_raw.shape[-1])\n","        label = torch.from_numpy(label)\n","        # train_set = train_raw.permute(0, 2, 1)\n","        # train_set = train_set.reshape(train_set.shape[0]*train_set.shape[1], -1)\n","        # print(\"train_set shape:{}\\nlabel shape:{}\\n\".format(train_set.shape, label.shape)) # [310284, 129]\n","\n","        # batch_x = torch.unsqueeze(train_set, dim=0) # [1, 263736, 129]\n","        batch_x = train_raw\n","        batch_x = Variable(batch_x.float())  # .cuda()\n","        batch_y = label.long()\n","\n","        optimizer.zero_grad()\n","        output = model(batch_x)  # ,hidden = model(batch_x,None)\n","\n","        # toc = time.perf_counter()\n","        # print(f\"test epochs time in {toc - tic:0.4f} seconds\")\n","\n","        _, predicted_train = torch.max(output.data, 1)\n","        assert(len(predicted_train)==len(batch_y))\n","        correct_all += sum(batch_y.eq(predicted_train))\n","        train_length += len(batch_y)\n","\n","        predicted_train_csv.append(predicted_train.cpu().detach().numpy())\n","        real_train_csv.append(batch_y.cpu().detach().numpy())\n","\n","        loss = criterion(output, batch_y.squeeze())#.float().reshape(-1, 1)\n","        total_loss += loss\n","        loss.backward()\n","        optimizer.step()\n","    print('\\n************************************************************************************************')\n","    print(\"Epoch {}/{}:, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n","        epoch+1,\n","        max_epochs,\n","        float(total_loss / train_length),\n","        float(optimizer.param_groups[0]['lr'])))\n","    print('train_acc:{}\\n'.format(correct_all/train_length))"],"metadata":{"id":"WqWx6X0bMmpF"},"execution_count":null,"outputs":[]}]}